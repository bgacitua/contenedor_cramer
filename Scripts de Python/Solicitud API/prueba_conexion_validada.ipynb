{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50b307b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTACI√ìN DE LIBRER√çAS ===\n",
    "import os                   \n",
    "import requests             \n",
    "import pandas as pd         \n",
    "import json                 \n",
    "from dotenv import load_dotenv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26b4505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "URL = \"https://cramer.buk.cl/apidocs#!/Inasistencias/get_absences_absence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "193df35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Token encontrado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# === AUTENTICACI√ìN Y HEADERS ===\n",
    "# Obtiene el token de autenticaci√≥n desde variable de entorno (m√°s seguro)\n",
    "TOKEN = os.getenv(\"TOKEN\")\n",
    "if not TOKEN:\n",
    "    # Si no encuentra el token, termina el programa con mensaje de error\n",
    "    raise SystemExit(\"ERROR: Define la variable de entorno BUK_AUTH_TOKEN con tu token\")\n",
    "\n",
    "print(\"‚úÖ Token encontrado exitosamente\")\n",
    "\n",
    "# Configura los headers que se enviar√°n en cada petici√≥n HTTP\n",
    "HEADERS = {\n",
    "    \"auth_token\": TOKEN,           # Token de autenticaci√≥n para la API\n",
    "    \"Accept\": \"application/json\",  # Le dice al servidor que esperamos respuesta en JSON\n",
    "    \"Content-Type\": \"application/json\"  # Especifica el tipo de contenido que enviamos\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6db05822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FUNCI√ìN MEJORADA PARA M√öLTIPLES ENDPOINTS CON FILTRO DE FECHAS ===\n",
    "from datetime import datetime, date\n",
    "\n",
    "def fetch_data_from_multiple_endpoints(fecha_inicio=\"2025-05-01\", fecha_fin=None):\n",
    "    \"\"\"\n",
    "    Obtiene datos de m√∫ltiples endpoints de BUK con filtro de fechas y los combina.\n",
    "    Maneja paginaci√≥n autom√°ticamente para cada endpoint.\n",
    "    \n",
    "    Args:\n",
    "        fecha_inicio (str): Fecha de inicio en formato 'YYYY-MM-DD'. Por defecto '2025-05-01'\n",
    "        fecha_fin (str): Fecha de fin en formato 'YYYY-MM-DD'. Si es None, usa fecha actual\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (datos_combinados, datos_por_endpoint, info_fechas)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Procesar fechas\n",
    "    if fecha_fin is None:\n",
    "        fecha_fin = date.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Validar formato de fechas\n",
    "    try:\n",
    "        datetime.strptime(fecha_inicio, '%Y-%m-%d')\n",
    "        datetime.strptime(fecha_fin, '%Y-%m-%d')\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Formato de fecha inv√°lido. Usa 'YYYY-MM-DD'. Error: {e}\")\n",
    "    \n",
    "    # Informaci√≥n de fechas para retornar\n",
    "    info_fechas = {\n",
    "        'fecha_inicio': fecha_inicio,\n",
    "        'fecha_fin': fecha_fin,\n",
    "        'fecha_extraccion': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    # Configuraci√≥n de endpoints\n",
    "    base_url = \"https://cramer.buk.cl/api/v1/chile\"\n",
    "    endpoints = {\n",
    "        \"inasistencias\": \"/absences/absence\",\n",
    "        \"licencias\": \"/absences/licence\", \n",
    "        \"permisos\": \"/absences/permission\"\n",
    "    }\n",
    "    \n",
    "    # Diccionario para almacenar datos de cada endpoint\n",
    "    all_data = {}\n",
    "    combined_records = []\n",
    "    \n",
    "    print(\"INICIANDO EXTRACCI√ìN DE M√öLTIPLES ENDPOINTS BUK CON FILTRO DE FECHAS\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Per√≠odo: {fecha_inicio} a {fecha_fin}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Iterar por cada endpoint\n",
    "    for endpoint_name, endpoint_path in endpoints.items():\n",
    "        print(f\"\\nPROCESANDO ENDPOINT: {endpoint_name.upper()}\")\n",
    "        print(f\"URL: {base_url}{endpoint_path}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Construir URL completa con par√°metros de fecha\n",
    "        url = f\"{base_url}{endpoint_path}\"\n",
    "        records_from_endpoint = []\n",
    "        page_count = 0\n",
    "        \n",
    "        # Bucle de paginaci√≥n para cada endpoint\n",
    "        while url:\n",
    "            try:\n",
    "                print(f\"üìÑ P√°gina {page_count + 1}...\")\n",
    "                \n",
    "                # Preparar par√°metros de la petici√≥n con filtro de fechas\n",
    "                params = {\n",
    "                    'from': fecha_inicio,\n",
    "                    'to': fecha_fin\n",
    "                }\n",
    "                \n",
    "                # Realizar petici√≥n con par√°metros de fecha\n",
    "                response = requests.get(url, headers=HEADERS, params=params, timeout=15)\n",
    "                response.raise_for_status()\n",
    "                \n",
    "                # Procesar respuesta\n",
    "                json_data = response.json()\n",
    "                \n",
    "                # Extraer datos (estructura t√≠pica de BUK)\n",
    "                page_data = json_data.get(\"data\", [])\n",
    "                \n",
    "                if not page_data:\n",
    "                    print(f\"   ‚ÑπÔ∏è No hay datos en esta p√°gina para el per√≠odo especificado\")\n",
    "                    break\n",
    "                \n",
    "                # Agregar metadatos a cada registro\n",
    "                for record in page_data:\n",
    "                    if isinstance(record, dict):\n",
    "                        record['_source_endpoint'] = endpoint_name\n",
    "                        record['_source_url'] = f\"{base_url}{endpoint_path}\"\n",
    "                        record['_fecha_extraccion'] = info_fechas['fecha_extraccion']\n",
    "                \n",
    "                records_from_endpoint.extend(page_data)\n",
    "                print(f\"   ‚úÖ {len(page_data)} registros obtenidos (per√≠odo: {fecha_inicio} a {fecha_fin})\")\n",
    "                \n",
    "                # Buscar siguiente p√°gina\n",
    "                pagination_info = json_data.get(\"pagination\", {})\n",
    "                next_url = pagination_info.get(\"next\")\n",
    "                \n",
    "                if next_url:\n",
    "                    # Mantener los par√°metros de fecha en la siguiente p√°gina\n",
    "                    url = next_url\n",
    "                else:\n",
    "                    url = None  # No hay m√°s p√°ginas\n",
    "                \n",
    "                page_count += 1\n",
    "                \n",
    "            except requests.HTTPError as e:\n",
    "                print(f\"‚ùå Error HTTP: {e}\")\n",
    "                print(f\"üìä Status Code: {getattr(e.response, 'status_code', 'N/A')}\")\n",
    "                if hasattr(e.response, 'text'):\n",
    "                    print(f\"üìÑ Respuesta: {e.response.text[:300]}...\")\n",
    "                break\n",
    "                \n",
    "            except requests.RequestException as e:\n",
    "                print(f\"üåê Error de conexi√≥n: {e}\")\n",
    "                break\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(f\"üìã Error JSON: {e}\")\n",
    "                if 'response' in locals():\n",
    "                    print(f\"üìÑ Respuesta: {response.text[:300]}...\")\n",
    "                break\n",
    "        \n",
    "        # Guardar resultados del endpoint\n",
    "        all_data[endpoint_name] = records_from_endpoint\n",
    "        combined_records.extend(records_from_endpoint)\n",
    "        \n",
    "        print(f\"üìä Total {endpoint_name}: {len(records_from_endpoint)} registros en {page_count} p√°ginas\")\n",
    "        print(f\"üìÖ Per√≠odo procesado: {fecha_inicio} a {fecha_fin}\")\n",
    "    \n",
    "    # Resumen final\n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(f\"üìà RESUMEN DE EXTRACCI√ìN COMPLETA CON FILTRO DE FECHAS:\")\n",
    "    print(f\"üìÖ Per√≠odo extra√≠do: {fecha_inicio} a {fecha_fin}\")\n",
    "    print(f\"üî¢ Total endpoints procesados: {len(endpoints)}\")\n",
    "    \n",
    "    for endpoint_name, records in all_data.items():\n",
    "        print(f\"   üìä {endpoint_name.capitalize()}: {len(records)} registros\")\n",
    "    \n",
    "    print(f\"üéØ TOTAL COMBINADO: {len(combined_records)} registros\")\n",
    "    print(f\"‚è∞ Fecha de extracci√≥n: {info_fechas['fecha_extraccion']}\")\n",
    "    print(f\"=\"*70)\n",
    "    \n",
    "    return combined_records, all_data, info_fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4dfc53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DETALLES DE LOS ENDPOINTS CONFIGURADOS\n",
      "============================================================\n",
      "\n",
      "üîó ENDPOINT: INASISTENCIAS\n",
      "   üìç URL completa: https://cramer.buk.cl/api/v1/chile/absences/absence\n",
      "   üîß M√©todo HTTP: GET\n",
      "   üìù Descripci√≥n: Obtiene registros de inasistencias/ausencias\n",
      "   üìÖ Filtros de fecha: Soporta par√°metros 'from' y 'to'\n",
      "   üìÑ Paginaci√≥n: S√≠ (autom√°tica)\n",
      "\n",
      "üîó ENDPOINT: LICENCIAS\n",
      "   üìç URL completa: https://cramer.buk.cl/api/v1/chile/absences/licence\n",
      "   üîß M√©todo HTTP: GET\n",
      "   üìù Descripci√≥n: Obtiene registros de licencias m√©dicas\n",
      "   üìÖ Filtros de fecha: Soporta par√°metros 'from' y 'to'\n",
      "   üìÑ Paginaci√≥n: S√≠ (autom√°tica)\n",
      "\n",
      "üîó ENDPOINT: PERMISOS\n",
      "   üìç URL completa: https://cramer.buk.cl/api/v1/chile/absences/permission\n",
      "   üîß M√©todo HTTP: GET\n",
      "   üìù Descripci√≥n: Obtiene registros de permisos\n",
      "   üìÖ Filtros de fecha: Soporta par√°metros 'from' y 'to'\n",
      "   üìÑ Paginaci√≥n: S√≠ (autom√°tica)\n",
      "\n",
      "‚úÖ CONFIRMACI√ìN:\n",
      "   ‚Ä¢ Todos los endpoints utilizan m√©todo GET\n",
      "   ‚Ä¢ Todos soportan filtros de fecha via query parameters\n",
      "   ‚Ä¢ La autenticaci√≥n se realiza via header 'auth_token'\n",
      "   ‚Ä¢ Los par√°metros de fecha van en la URL como ?from=YYYY-MM-DD&to=YYYY-MM-DD\n",
      "\n",
      "üåê EJEMPLO DE URL COMPLETA CON FILTROS:\n",
      "   https://cramer.buk.cl/api/v1/chile/absences/absence?from=2025-05-01&to=2025-08-25\n",
      "\n",
      "üìã ESTRUCTURA DE LA PETICI√ìN:\n",
      "   ‚Ä¢ M√©todo: GET\n",
      "   ‚Ä¢ Headers: auth_token, Accept, Content-Type\n",
      "   ‚Ä¢ Query Params: from, to\n",
      "   ‚Ä¢ Timeout: 15 segundos\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# === INFORMACI√ìN DETALLADA DE LOS ENDPOINTS ===\n",
    "print(\"üìä DETALLES DE LOS ENDPOINTS CONFIGURADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Informaci√≥n sobre los endpoints (sin modificar la variable original)\n",
    "base_url = \"https://cramer.buk.cl/api/v1/chile\"\n",
    "endpoint_info = {\n",
    "    \"inasistencias\": {\n",
    "        \"path\": \"/absences/absence\",\n",
    "        \"method\": \"GET\",\n",
    "        \"descripcion\": \"Obtiene registros de inasistencias/ausencias\",\n",
    "        \"filtros_fecha\": \"Soporta par√°metros 'from' y 'to'\",\n",
    "        \"paginacion\": \"S√≠ (autom√°tica)\"\n",
    "    },\n",
    "    \"licencias\": {\n",
    "        \"path\": \"/absences/licence\",\n",
    "        \"method\": \"GET\", \n",
    "        \"descripcion\": \"Obtiene registros de licencias m√©dicas\",\n",
    "        \"filtros_fecha\": \"Soporta par√°metros 'from' y 'to'\",\n",
    "        \"paginacion\": \"S√≠ (autom√°tica)\"\n",
    "    },\n",
    "    \"permisos\": {\n",
    "        \"path\": \"/absences/permission\",\n",
    "        \"method\": \"GET\",\n",
    "        \"descripcion\": \"Obtiene registros de permisos\",\n",
    "        \"filtros_fecha\": \"Soporta par√°metros 'from' y 'to'\",\n",
    "        \"paginacion\": \"S√≠ (autom√°tica)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for nombre, info in endpoint_info.items():\n",
    "    print(f\"\\nüîó ENDPOINT: {nombre.upper()}\")\n",
    "    print(f\"   üìç URL completa: {base_url}{info['path']}\")\n",
    "    print(f\"   üîß M√©todo HTTP: {info['method']}\")\n",
    "    print(f\"   üìù Descripci√≥n: {info['descripcion']}\")\n",
    "    print(f\"   üìÖ Filtros de fecha: {info['filtros_fecha']}\")\n",
    "    print(f\"   üìÑ Paginaci√≥n: {info['paginacion']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ CONFIRMACI√ìN:\")\n",
    "print(f\"   ‚Ä¢ Todos los endpoints utilizan m√©todo GET\")\n",
    "print(f\"   ‚Ä¢ Todos soportan filtros de fecha via query parameters\")\n",
    "print(f\"   ‚Ä¢ La autenticaci√≥n se realiza via header 'auth_token'\")\n",
    "print(f\"   ‚Ä¢ Los par√°metros de fecha van en la URL como ?from=YYYY-MM-DD&to=YYYY-MM-DD\")\n",
    "\n",
    "print(f\"\\nüåê EJEMPLO DE URL COMPLETA CON FILTROS:\")\n",
    "ejemplo_fecha_inicio = \"2025-05-01\"\n",
    "ejemplo_fecha_fin = \"2025-08-25\"\n",
    "print(f\"   {base_url}/absences/absence?from={ejemplo_fecha_inicio}&to={ejemplo_fecha_fin}\")\n",
    "print(f\"\\nüìã ESTRUCTURA DE LA PETICI√ìN:\")\n",
    "print(f\"   ‚Ä¢ M√©todo: GET\")\n",
    "print(f\"   ‚Ä¢ Headers: auth_token, Accept, Content-Type\")\n",
    "print(f\"   ‚Ä¢ Query Params: from, to\")\n",
    "print(f\"   ‚Ä¢ Timeout: 15 segundos\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fca6c41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ EXTRAYENDO DATOS DE M√öLTIPLES ENDPOINTS BUK CON FILTRO DE FECHAS\n",
      "======================================================================\n",
      " Configuraci√≥n de fechas:\n",
      "   ‚Ä¢ Fecha inicio: 2025-05-01\n",
      "   ‚Ä¢ Fecha fin: Fecha actual\n",
      "\n",
      "üì° Obteniendo datos desde m√∫ltiples APIs con filtro de fechas...\n",
      "INICIANDO EXTRACCI√ìN DE M√öLTIPLES ENDPOINTS BUK CON FILTRO DE FECHAS\n",
      "======================================================================\n",
      "Per√≠odo: 2025-05-01 a 2025-08-26\n",
      "======================================================================\n",
      "\n",
      "PROCESANDO ENDPOINT: INASISTENCIAS\n",
      "URL: https://cramer.buk.cl/api/v1/chile/absences/absence\n",
      "--------------------------------------------------\n",
      "üìÑ P√°gina 1...\n",
      "   ‚úÖ 25 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìÑ P√°gina 2...\n",
      "   ‚úÖ 11 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìä Total inasistencias: 36 registros en 2 p√°ginas\n",
      "üìÖ Per√≠odo procesado: 2025-05-01 a 2025-08-26\n",
      "\n",
      "PROCESANDO ENDPOINT: LICENCIAS\n",
      "URL: https://cramer.buk.cl/api/v1/chile/absences/licence\n",
      "--------------------------------------------------\n",
      "üìÑ P√°gina 1...\n",
      "   ‚úÖ 25 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìÑ P√°gina 2...\n",
      "   ‚úÖ 25 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìÑ P√°gina 3...\n",
      "   ‚úÖ 25 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìÑ P√°gina 4...\n",
      "   ‚úÖ 25 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìÑ P√°gina 5...\n",
      "   ‚úÖ 25 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìÑ P√°gina 6...\n",
      "   ‚úÖ 25 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìÑ P√°gina 7...\n",
      "   ‚úÖ 12 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìä Total licencias: 162 registros en 7 p√°ginas\n",
      "üìÖ Per√≠odo procesado: 2025-05-01 a 2025-08-26\n",
      "\n",
      "PROCESANDO ENDPOINT: PERMISOS\n",
      "URL: https://cramer.buk.cl/api/v1/chile/absences/permission\n",
      "--------------------------------------------------\n",
      "üìÑ P√°gina 1...\n",
      "   ‚úÖ 25 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìÑ P√°gina 2...\n",
      "   ‚úÖ 11 registros obtenidos (per√≠odo: 2025-05-01 a 2025-08-26)\n",
      "üìä Total permisos: 36 registros en 2 p√°ginas\n",
      "üìÖ Per√≠odo procesado: 2025-05-01 a 2025-08-26\n",
      "\n",
      "======================================================================\n",
      "üìà RESUMEN DE EXTRACCI√ìN COMPLETA CON FILTRO DE FECHAS:\n",
      "üìÖ Per√≠odo extra√≠do: 2025-05-01 a 2025-08-26\n",
      "üî¢ Total endpoints procesados: 3\n",
      "   üìä Inasistencias: 36 registros\n",
      "   üìä Licencias: 162 registros\n",
      "   üìä Permisos: 36 registros\n",
      "üéØ TOTAL COMBINADO: 234 registros\n",
      "‚è∞ Fecha de extracci√≥n: 2025-08-26 11:30:00\n",
      "======================================================================\n",
      "\n",
      "‚úÖ EXTRACCI√ìN EXITOSA!\n",
      "   üìä Total registros combinados: 234\n",
      "   üìÖ Per√≠odo real extra√≠do: 2025-05-01 a 2025-08-26\n",
      "\n",
      "üîÑ Creando DataFrame combinado...\n",
      "   üìä DataFrame combinado: 234 filas √ó 37 columnas\n",
      "\n",
      "üìã DESGLOSE POR ENDPOINT:\n",
      "   ‚Ä¢ Licencias: 162 registros (69.2%)\n",
      "   ‚Ä¢ Inasistencias: 36 registros (15.4%)\n",
      "   ‚Ä¢ Permisos: 36 registros (15.4%)\n",
      "\n",
      "üìã COLUMNAS DISPONIBLES (37):\n",
      "    1- 3. id | start_date | end_date\n",
      "    4- 6. days_count | day_percent | contribution_days\n",
      "    7- 9. workday_stage | application_date | application_end_date\n",
      "   10-12. justification | employee_id | status\n",
      "   13-15. created_at | updated_at | absence_type_id\n",
      "   16-18. absence_type_code | _source_endpoint | _source_url\n",
      "   19-21. _fecha_extraccion | type | licence_type_id\n",
      "   22-24. licence_type_code | licence_type | motivo\n",
      "   25-27. format | licence_number | medic_rut\n",
      "   28-30. medic_name | risk_type | sequela\n",
      "   31-33. incapacities_control | permission_type_id | permission_type_code\n",
      "   34-36. paid | time_measure | start_time\n",
      "   37-37. end_time\n",
      "\n",
      "üìÑ MUESTRA DE DATOS COMBINADOS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_count</th>\n",
       "      <th>day_percent</th>\n",
       "      <th>contribution_days</th>\n",
       "      <th>workday_stage</th>\n",
       "      <th>application_date</th>\n",
       "      <th>application_end_date</th>\n",
       "      <th>justification</th>\n",
       "      <th>...</th>\n",
       "      <th>medic_name</th>\n",
       "      <th>risk_type</th>\n",
       "      <th>sequela</th>\n",
       "      <th>incapacities_control</th>\n",
       "      <th>permission_type_id</th>\n",
       "      <th>permission_type_code</th>\n",
       "      <th>paid</th>\n",
       "      <th>time_measure</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105184</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>Ausencia sin licencia m√©dica</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105185</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>Ausencia sin licencia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105250</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>Tramite personal, informado por Manuel Gamboa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105283</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>Fallecimiento abuelita, se regal√≥ 2 d√≠as y el ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105547</td>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>2025-05-13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>2025-05-16</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  start_date    end_date  days_count  day_percent  contribution_days  \\\n",
       "0  105184  2025-05-05  2025-05-05         1.0          1.0                0.0   \n",
       "1  105185  2025-05-08  2025-05-08         1.0          1.0                0.0   \n",
       "2  105250  2025-05-02  2025-05-02         1.0          1.0                0.0   \n",
       "3  105283  2025-05-08  2025-05-08         1.0          1.0                0.0   \n",
       "4  105547  2025-05-11  2025-05-13         3.0          1.0                0.0   \n",
       "\n",
       "      workday_stage application_date application_end_date  \\\n",
       "0  full_working_day       2025-05-05           2025-05-05   \n",
       "1  full_working_day       2025-05-08           2025-05-08   \n",
       "2  full_working_day       2025-05-02           2025-05-02   \n",
       "3  full_working_day       2025-05-08           2025-05-08   \n",
       "4  full_working_day       2025-05-14           2025-05-16   \n",
       "\n",
       "                                       justification  ...  medic_name  \\\n",
       "0                       Ausencia sin licencia m√©dica  ...         NaN   \n",
       "1                              Ausencia sin licencia  ...         NaN   \n",
       "2      Tramite personal, informado por Manuel Gamboa  ...         NaN   \n",
       "3  Fallecimiento abuelita, se regal√≥ 2 d√≠as y el ...  ...         NaN   \n",
       "4                                                     ...         NaN   \n",
       "\n",
       "  risk_type sequela incapacities_control  permission_type_id  \\\n",
       "0       NaN     NaN                  NaN                 NaN   \n",
       "1       NaN     NaN                  NaN                 NaN   \n",
       "2       NaN     NaN                  NaN                 NaN   \n",
       "3       NaN     NaN                  NaN                 NaN   \n",
       "4       NaN     NaN                  NaN                 NaN   \n",
       "\n",
       "  permission_type_code paid time_measure start_time end_time  \n",
       "0                  NaN  NaN          NaN        NaN      NaN  \n",
       "1                  NaN  NaN          NaN        NaN      NaN  \n",
       "2                  NaN  NaN          NaN        NaN      NaN  \n",
       "3                  NaN  NaN          NaN        NaN      NaN  \n",
       "4                  NaN  NaN          NaN        NaN      NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÖ Procesando campos de fecha...\n",
      "   ‚úÖ Campo 'start_date' convertido a fecha\n",
      "   ‚úÖ Campo 'end_date' convertido a fecha\n",
      "   ‚úÖ Campo 'application_date' convertido a fecha\n",
      "   ‚úÖ Campo 'application_end_date' convertido a fecha\n",
      "   ‚úÖ Campo 'created_at' convertido a fecha\n",
      "   ‚úÖ Campo 'updated_at' convertido a fecha\n",
      "   üìä Total campos de fecha convertidos: 6\n",
      "\n",
      "üìà VALIDACI√ìN DE RANGO DE FECHAS:\n",
      "   ‚Ä¢ Fecha m√≠nima en datos: 2025-02-14\n",
      "   ‚Ä¢ Fecha m√°xima en datos: 2025-08-26\n",
      "   ‚Ä¢ Registros con fechas v√°lidas: 234\n",
      "\n",
      "üíæ DATOS GUARDADOS:\n",
      "   ‚Ä¢ Variable 'df_buk_combinado': DataFrame con todos los datos\n",
      "   ‚Ä¢ Variable 'datos_por_endpoint': Diccionario separado por endpoint\n",
      "   ‚Ä¢ Variable 'info_extraccion': Informaci√≥n del rango de fechas usado\n",
      "\n",
      "üìà ESTAD√çSTICAS FINALES:\n",
      "   ‚Ä¢ Total registros: 234\n",
      "   ‚Ä¢ Total columnas: 37\n",
      "   ‚Ä¢ Per√≠odo: 2025-05-01 a 2025-08-26\n",
      "   ‚Ä¢ Memoria utilizada: 0.29 MB\n",
      "\n",
      "üîç CAMPOS PRINCIPALES POR ENDPOINT:\n",
      "   ‚Ä¢ Inasistencias:\n",
      "     - id: 36 registros\n",
      "     - start_date: 36 registros\n",
      "     - end_date: 36 registros\n",
      "     - days_count: 36 registros\n",
      "     - day_percent: 36 registros\n",
      "   ‚Ä¢ Licencias:\n",
      "     - id: 162 registros\n",
      "     - start_date: 162 registros\n",
      "     - end_date: 162 registros\n",
      "     - days_count: 162 registros\n",
      "     - day_percent: 162 registros\n",
      "   ‚Ä¢ Permisos:\n",
      "     - id: 36 registros\n",
      "     - start_date: 36 registros\n",
      "     - end_date: 36 registros\n",
      "     - days_count: 36 registros\n",
      "     - day_percent: 36 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgacitua\\AppData\\Local\\Temp\\ipykernel_22696\\1560132489.py:59: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df_combinado[column] = pd.to_datetime(df_combinado[column], errors=\"coerce\")\n",
      "C:\\Users\\bgacitua\\AppData\\Local\\Temp\\ipykernel_22696\\1560132489.py:59: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df_combinado[column] = pd.to_datetime(df_combinado[column], errors=\"coerce\")\n"
     ]
    }
   ],
   "source": [
    "# === EXTRACCI√ìN COMBINADA CON RANGO DE FECHAS ===\n",
    "print(\"üöÄ EXTRAYENDO DATOS DE M√öLTIPLES ENDPOINTS BUK CON FILTRO DE FECHAS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # CONFIGURAR FECHAS AQU√ç:\n",
    "    fecha_inicio = \"2025-05-01\"  \n",
    "    fecha_fin = None             \n",
    "    \n",
    "    print(f\" Configuraci√≥n de fechas:\")\n",
    "    print(f\"   ‚Ä¢ Fecha inicio: {fecha_inicio}\")\n",
    "    print(f\"   ‚Ä¢ Fecha fin: {'Fecha actual' if fecha_fin is None else fecha_fin}\")\n",
    "    \n",
    "    # Paso 1: Extraer de todos los endpoints CON RANGO DE FECHAS\n",
    "    print(f\"\\nüì° Obteniendo datos desde m√∫ltiples APIs con filtro de fechas...\")\n",
    "    datos_combinados, datos_por_endpoint, info_fechas = fetch_data_from_multiple_endpoints(\n",
    "        fecha_inicio=fecha_inicio, \n",
    "        fecha_fin=fecha_fin\n",
    "    )\n",
    "    \n",
    "    if datos_combinados:\n",
    "        print(f\"\\n‚úÖ EXTRACCI√ìN EXITOSA!\")\n",
    "        print(f\"   üìä Total registros combinados: {len(datos_combinados)}\")\n",
    "        print(f\"   üìÖ Per√≠odo real extra√≠do: {info_fechas['fecha_inicio']} a {info_fechas['fecha_fin']}\")\n",
    "        \n",
    "        # Paso 2: Convertir a DataFrame combinado\n",
    "        print(f\"\\nüîÑ Creando DataFrame combinado...\")\n",
    "        df_combinado = pd.json_normalize(datos_combinados, sep=\"_\")\n",
    "        \n",
    "        print(f\"   üìä DataFrame combinado: {df_combinado.shape[0]} filas √ó {df_combinado.shape[1]} columnas\")\n",
    "        \n",
    "        # Paso 3: Mostrar informaci√≥n por endpoint\n",
    "        print(f\"\\nüìã DESGLOSE POR ENDPOINT:\")\n",
    "        if '_source_endpoint' in df_combinado.columns:\n",
    "            conteo_por_endpoint = df_combinado['_source_endpoint'].value_counts()\n",
    "            for endpoint, cantidad in conteo_por_endpoint.items():\n",
    "                porcentaje = (cantidad / len(df_combinado)) * 100\n",
    "                print(f\"   ‚Ä¢ {endpoint.capitalize()}: {cantidad} registros ({porcentaje:.1f}%)\")\n",
    "        \n",
    "        # Paso 4: Mostrar columnas disponibles\n",
    "        print(f\"\\nüìã COLUMNAS DISPONIBLES ({len(df_combinado.columns)}):\")\n",
    "        columnas_por_fila = 3\n",
    "        columnas = list(df_combinado.columns)\n",
    "        \n",
    "        for i in range(0, len(columnas), columnas_por_fila):\n",
    "            fila_columnas = columnas[i:i+columnas_por_fila]\n",
    "            print(f\"   {i+1:2d}-{min(i+columnas_por_fila, len(columnas)):2d}. {' | '.join(fila_columnas)}\")\n",
    "        \n",
    "        # Paso 5: Mostrar muestra de datos\n",
    "        print(f\"\\nüìÑ MUESTRA DE DATOS COMBINADOS:\")\n",
    "        display(df_combinado.head())\n",
    "        \n",
    "        # Paso 6: Procesar campos de fecha\n",
    "        print(f\"\\nüìÖ Procesando campos de fecha...\")\n",
    "        date_keywords = [\"start_date\", \"end_date\", \"application_date\", \"created_at\", \"updated_at\"]\n",
    "        fechas_convertidas = 0\n",
    "        for column in df_combinado.columns:\n",
    "            if any(keyword in column.lower() for keyword in date_keywords):\n",
    "                df_combinado[column] = pd.to_datetime(df_combinado[column], errors=\"coerce\")\n",
    "                fechas_convertidas += 1\n",
    "                print(f\"   ‚úÖ Campo '{column}' convertido a fecha\")\n",
    "        \n",
    "        print(f\"   üìä Total campos de fecha convertidos: {fechas_convertidas}\")\n",
    "        \n",
    "        # Paso 7: Validar rango de fechas en los datos\n",
    "        if 'start_date' in df_combinado.columns:\n",
    "            df_fechas_validas = df_combinado.dropna(subset=['start_date'])\n",
    "            if len(df_fechas_validas) > 0:\n",
    "                fecha_min_datos = df_fechas_validas['start_date'].min()\n",
    "                fecha_max_datos = df_fechas_validas['start_date'].max()\n",
    "                print(f\"\\nüìà VALIDACI√ìN DE RANGO DE FECHAS:\")\n",
    "                print(f\"   ‚Ä¢ Fecha m√≠nima en datos: {fecha_min_datos.date()}\")\n",
    "                print(f\"   ‚Ä¢ Fecha m√°xima en datos: {fecha_max_datos.date()}\")\n",
    "                print(f\"   ‚Ä¢ Registros con fechas v√°lidas: {len(df_fechas_validas):,}\")\n",
    "        \n",
    "        # Paso 8: Guardar en variables globales\n",
    "        globals()['df_buk_combinado'] = df_combinado\n",
    "        globals()['datos_por_endpoint'] = datos_por_endpoint\n",
    "        globals()['info_extraccion'] = info_fechas\n",
    "        \n",
    "        print(f\"\\nüíæ DATOS GUARDADOS:\")\n",
    "        print(f\"   ‚Ä¢ Variable 'df_buk_combinado': DataFrame con todos los datos\")\n",
    "        print(f\"   ‚Ä¢ Variable 'datos_por_endpoint': Diccionario separado por endpoint\")\n",
    "        print(f\"   ‚Ä¢ Variable 'info_extraccion': Informaci√≥n del rango de fechas usado\")\n",
    "        \n",
    "        # Paso 9: Estad√≠sticas finales\n",
    "        print(f\"\\nüìà ESTAD√çSTICAS FINALES:\")\n",
    "        print(f\"   ‚Ä¢ Total registros: {len(df_combinado):,}\")\n",
    "        print(f\"   ‚Ä¢ Total columnas: {len(df_combinado.columns)}\")\n",
    "        print(f\"   ‚Ä¢ Per√≠odo: {info_fechas['fecha_inicio']} a {info_fechas['fecha_fin']}\")\n",
    "        print(f\"   ‚Ä¢ Memoria utilizada: {df_combinado.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "        \n",
    "        # Mostrar campos √∫nicos por endpoint\n",
    "        if '_source_endpoint' in df_combinado.columns:\n",
    "            print(f\"\\nüîç CAMPOS PRINCIPALES POR ENDPOINT:\")\n",
    "            for endpoint in df_combinado['_source_endpoint'].unique():\n",
    "                df_endpoint = df_combinado[df_combinado['_source_endpoint'] == endpoint]\n",
    "                campos_no_nulos = df_endpoint.notna().sum()\n",
    "                campos_principales = campos_no_nulos[campos_no_nulos > 0].head(5)\n",
    "                print(f\"   ‚Ä¢ {endpoint.capitalize()}:\")\n",
    "                for campo, cantidad in campos_principales.items():\n",
    "                    if campo not in ['_source_endpoint', '_source_url', '_fecha_extraccion']:\n",
    "                        print(f\"     - {campo}: {cantidad} registros\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No se pudieron obtener datos de ning√∫n endpoint\")\n",
    "        print(\"üí° Posibles causas:\")\n",
    "        print(\"   ‚Ä¢ Tu token de autenticaci√≥n no es v√°lido\")\n",
    "        print(\"   ‚Ä¢ Las URLs de los endpoints no son correctas\")\n",
    "        print(\"   ‚Ä¢ No hay datos en el rango de fechas especificado\")\n",
    "        print(\"   ‚Ä¢ Problemas de conectividad\")\n",
    "        print(f\"\\nüîß Sugerencias:\")\n",
    "        print(f\"   ‚Ä¢ Verifica tu token en la variable de entorno\")\n",
    "        print(f\"   ‚Ä¢ Prueba con un rango de fechas diferente\")\n",
    "        print(f\"   ‚Ä¢ Revisa los logs de error arriba\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"üí• Error inesperado: {e}\")\n",
    "    print(f\"   Tipo de error: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    print(f\"   Detalles: {traceback.format_exc()}\")\n",
    "    \n",
    "    # Informaci√≥n para debugging\n",
    "    print(f\"\\nüîß Para debugging:\")\n",
    "    print(f\"   ‚Ä¢ Verifica que HEADERS est√© definido\")\n",
    "    print(f\"   ‚Ä¢ Confirma que tienes conexi√≥n a internet\")\n",
    "    print(f\"   ‚Ä¢ Ejecuta las celdas anteriores primero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7be5e1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN√ÅLISIS DETALLADO POR ENDPOINT\n",
      "==================================================\n",
      "\n",
      "AN√ÅLISIS: INASISTENCIAS\n",
      "------------------------------\n",
      "Registros: 36\n",
      "Columnas: 19\n",
      "Columnas principales:\n",
      "      1. id (36 valores √∫nicos)\n",
      "      2. start_date (28 valores √∫nicos)\n",
      "      3. end_date (28 valores √∫nicos)\n",
      "      4. days_count (4 valores √∫nicos)\n",
      "      5. day_percent (1 valores √∫nicos)\n",
      "Muestra de datos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_count</th>\n",
       "      <th>day_percent</th>\n",
       "      <th>contribution_days</th>\n",
       "      <th>workday_stage</th>\n",
       "      <th>application_date</th>\n",
       "      <th>application_end_date</th>\n",
       "      <th>justification</th>\n",
       "      <th>employee_id</th>\n",
       "      <th>status</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>absence_type_id</th>\n",
       "      <th>absence_type_code</th>\n",
       "      <th>_source_endpoint</th>\n",
       "      <th>_source_url</th>\n",
       "      <th>_fecha_extraccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105184</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>Ausencia sin licencia m√©dica</td>\n",
       "      <td>6237</td>\n",
       "      <td>approved</td>\n",
       "      <td>2025-05-08T12:41:23.366-04:00</td>\n",
       "      <td>2025-05-08T12:41:23.366-04:00</td>\n",
       "      <td>2</td>\n",
       "      <td>ausencia</td>\n",
       "      <td>inasistencias</td>\n",
       "      <td>https://cramer.buk.cl/api/v1/chile/absences/ab...</td>\n",
       "      <td>2025-08-26 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105185</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>Ausencia sin licencia</td>\n",
       "      <td>4918</td>\n",
       "      <td>approved</td>\n",
       "      <td>2025-05-08T12:42:26.143-04:00</td>\n",
       "      <td>2025-05-08T12:42:26.143-04:00</td>\n",
       "      <td>2</td>\n",
       "      <td>ausencia</td>\n",
       "      <td>inasistencias</td>\n",
       "      <td>https://cramer.buk.cl/api/v1/chile/absences/ab...</td>\n",
       "      <td>2025-08-26 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105250</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>Tramite personal, informado por Manuel Gamboa</td>\n",
       "      <td>4191</td>\n",
       "      <td>approved</td>\n",
       "      <td>2025-05-09T12:04:20.199-04:00</td>\n",
       "      <td>2025-05-09T12:04:20.199-04:00</td>\n",
       "      <td>2</td>\n",
       "      <td>ausencia</td>\n",
       "      <td>inasistencias</td>\n",
       "      <td>https://cramer.buk.cl/api/v1/chile/absences/ab...</td>\n",
       "      <td>2025-08-26 11:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  start_date    end_date  days_count  day_percent  contribution_days  \\\n",
       "0  105184  2025-05-05  2025-05-05         1.0            1                0.0   \n",
       "1  105185  2025-05-08  2025-05-08         1.0            1                0.0   \n",
       "2  105250  2025-05-02  2025-05-02         1.0            1                0.0   \n",
       "\n",
       "      workday_stage application_date application_end_date  \\\n",
       "0  full_working_day       2025-05-05           2025-05-05   \n",
       "1  full_working_day       2025-05-08           2025-05-08   \n",
       "2  full_working_day       2025-05-02           2025-05-02   \n",
       "\n",
       "                                   justification  employee_id    status  \\\n",
       "0                   Ausencia sin licencia m√©dica         6237  approved   \n",
       "1                          Ausencia sin licencia         4918  approved   \n",
       "2  Tramite personal, informado por Manuel Gamboa         4191  approved   \n",
       "\n",
       "                      created_at                     updated_at  \\\n",
       "0  2025-05-08T12:41:23.366-04:00  2025-05-08T12:41:23.366-04:00   \n",
       "1  2025-05-08T12:42:26.143-04:00  2025-05-08T12:42:26.143-04:00   \n",
       "2  2025-05-09T12:04:20.199-04:00  2025-05-09T12:04:20.199-04:00   \n",
       "\n",
       "   absence_type_id absence_type_code _source_endpoint  \\\n",
       "0                2          ausencia    inasistencias   \n",
       "1                2          ausencia    inasistencias   \n",
       "2                2          ausencia    inasistencias   \n",
       "\n",
       "                                         _source_url    _fecha_extraccion  \n",
       "0  https://cramer.buk.cl/api/v1/chile/absences/ab...  2025-08-26 11:30:00  \n",
       "1  https://cramer.buk.cl/api/v1/chile/absences/ab...  2025-08-26 11:30:00  \n",
       "2  https://cramer.buk.cl/api/v1/chile/absences/ab...  2025-08-26 11:30:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en variable: df_inasistencias\n",
      "\n",
      "AN√ÅLISIS: LICENCIAS\n",
      "------------------------------\n",
      "Registros: 162\n",
      "Columnas: 29\n",
      "Columnas principales:\n",
      "      1. id (162 valores √∫nicos)\n",
      "      2. start_date (87 valores √∫nicos)\n",
      "      3. end_date (88 valores √∫nicos)\n",
      "      4. days_count (23 valores √∫nicos)\n",
      "      5. day_percent (1 valores √∫nicos)\n",
      "Muestra de datos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_count</th>\n",
       "      <th>day_percent</th>\n",
       "      <th>contribution_days</th>\n",
       "      <th>workday_stage</th>\n",
       "      <th>application_date</th>\n",
       "      <th>application_end_date</th>\n",
       "      <th>justification</th>\n",
       "      <th>...</th>\n",
       "      <th>format</th>\n",
       "      <th>licence_number</th>\n",
       "      <th>medic_rut</th>\n",
       "      <th>medic_name</th>\n",
       "      <th>risk_type</th>\n",
       "      <th>sequela</th>\n",
       "      <th>incapacities_control</th>\n",
       "      <th>_source_endpoint</th>\n",
       "      <th>_source_url</th>\n",
       "      <th>_fecha_extraccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102676</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-02-14</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>electronica</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>licencias</td>\n",
       "      <td>https://cramer.buk.cl/api/v1/chile/absences/li...</td>\n",
       "      <td>2025-08-26 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104029</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>Licencia com√∫n</td>\n",
       "      <td>...</td>\n",
       "      <td>electronica</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>licencias</td>\n",
       "      <td>https://cramer.buk.cl/api/v1/chile/absences/li...</td>\n",
       "      <td>2025-08-26 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104129</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>2025-05-04</td>\n",
       "      <td>Licencia normal</td>\n",
       "      <td>...</td>\n",
       "      <td>electronica</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>licencias</td>\n",
       "      <td>https://cramer.buk.cl/api/v1/chile/absences/li...</td>\n",
       "      <td>2025-08-26 11:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  start_date    end_date  days_count  day_percent  contribution_days  \\\n",
       "0  102676  2025-02-14  2025-05-08        84.0            1                0.0   \n",
       "1  104029  2025-04-02  2025-05-01        30.0            1                0.0   \n",
       "2  104129  2025-04-05  2025-05-04        30.0            1                0.0   \n",
       "\n",
       "      workday_stage application_date application_end_date    justification  \\\n",
       "0  full_working_day       2025-02-14           2025-05-08                    \n",
       "1  full_working_day       2025-04-02           2025-05-01   Licencia com√∫n   \n",
       "2  full_working_day       2025-04-05           2025-05-04  Licencia normal   \n",
       "\n",
       "   ...       format licence_number medic_rut medic_name risk_type  sequela  \\\n",
       "0  ...  electronica                     None                 None     None   \n",
       "1  ...  electronica                     None                 None     None   \n",
       "2  ...  electronica                     None                 None     None   \n",
       "\n",
       "  incapacities_control _source_endpoint  \\\n",
       "0                 None        licencias   \n",
       "1                 None        licencias   \n",
       "2                 None        licencias   \n",
       "\n",
       "                                         _source_url    _fecha_extraccion  \n",
       "0  https://cramer.buk.cl/api/v1/chile/absences/li...  2025-08-26 11:30:00  \n",
       "1  https://cramer.buk.cl/api/v1/chile/absences/li...  2025-08-26 11:30:00  \n",
       "2  https://cramer.buk.cl/api/v1/chile/absences/li...  2025-08-26 11:30:00  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en variable: df_licencias\n",
      "\n",
      "AN√ÅLISIS: PERMISOS\n",
      "------------------------------\n",
      "Registros: 36\n",
      "Columnas: 23\n",
      "Columnas principales:\n",
      "      1. id (36 valores √∫nicos)\n",
      "      2. start_date (29 valores √∫nicos)\n",
      "      3. end_date (28 valores √∫nicos)\n",
      "      4. days_count (8 valores √∫nicos)\n",
      "      5. day_percent (2 valores √∫nicos)\n",
      "Muestra de datos:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_count</th>\n",
       "      <th>day_percent</th>\n",
       "      <th>contribution_days</th>\n",
       "      <th>workday_stage</th>\n",
       "      <th>application_date</th>\n",
       "      <th>application_end_date</th>\n",
       "      <th>justification</th>\n",
       "      <th>...</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>permission_type_id</th>\n",
       "      <th>permission_type_code</th>\n",
       "      <th>paid</th>\n",
       "      <th>time_measure</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>_source_endpoint</th>\n",
       "      <th>_source_url</th>\n",
       "      <th>_fecha_extraccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104986</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>Fallecimiento del abuelito</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-05-06T09:13:56.325-04:00</td>\n",
       "      <td>9</td>\n",
       "      <td>permiso_fallecimiento_cramer</td>\n",
       "      <td>True</td>\n",
       "      <td>per_day</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>permisos</td>\n",
       "      <td>https://cramer.buk.cl/api/v1/chile/absences/pe...</td>\n",
       "      <td>2025-08-26 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105448</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>Compensaci√≥n d√≠a domingo 30-03-2025. Respaldo ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-05-14T16:07:47.375-04:00</td>\n",
       "      <td>74</td>\n",
       "      <td>compensacion_por_viaje</td>\n",
       "      <td>True</td>\n",
       "      <td>per_day</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>permisos</td>\n",
       "      <td>https://cramer.buk.cl/api/v1/chile/absences/pe...</td>\n",
       "      <td>2025-08-26 11:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105449</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>Fallecimiento hermana</td>\n",
       "      <td>...</td>\n",
       "      <td>2025-05-14T16:27:10.517-04:00</td>\n",
       "      <td>8</td>\n",
       "      <td>permiso_fallecimiento_legal</td>\n",
       "      <td>True</td>\n",
       "      <td>per_day</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>permisos</td>\n",
       "      <td>https://cramer.buk.cl/api/v1/chile/absences/pe...</td>\n",
       "      <td>2025-08-26 11:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  start_date    end_date  days_count  day_percent  contribution_days  \\\n",
       "0  104986  2025-05-06  2025-05-07         2.0          1.0                0.0   \n",
       "1  105448  2025-05-22  2025-05-22         1.0          1.0                0.0   \n",
       "2  105449  2025-05-12  2025-05-15         4.0          1.0                0.0   \n",
       "\n",
       "      workday_stage application_date application_end_date  \\\n",
       "0  full_working_day       2025-05-06           2025-05-07   \n",
       "1  full_working_day       2025-05-22           2025-05-22   \n",
       "2  full_working_day       2025-05-12           2025-05-15   \n",
       "\n",
       "                                       justification  ...  \\\n",
       "0                         Fallecimiento del abuelito  ...   \n",
       "1  Compensaci√≥n d√≠a domingo 30-03-2025. Respaldo ...  ...   \n",
       "2                              Fallecimiento hermana  ...   \n",
       "\n",
       "                      updated_at permission_type_id  \\\n",
       "0  2025-05-06T09:13:56.325-04:00                  9   \n",
       "1  2025-05-14T16:07:47.375-04:00                 74   \n",
       "2  2025-05-14T16:27:10.517-04:00                  8   \n",
       "\n",
       "           permission_type_code  paid  time_measure start_time  end_time  \\\n",
       "0  permiso_fallecimiento_cramer  True       per_day       None      None   \n",
       "1        compensacion_por_viaje  True       per_day       None      None   \n",
       "2   permiso_fallecimiento_legal  True       per_day       None      None   \n",
       "\n",
       "  _source_endpoint                                        _source_url  \\\n",
       "0         permisos  https://cramer.buk.cl/api/v1/chile/absences/pe...   \n",
       "1         permisos  https://cramer.buk.cl/api/v1/chile/absences/pe...   \n",
       "2         permisos  https://cramer.buk.cl/api/v1/chile/absences/pe...   \n",
       "\n",
       "     _fecha_extraccion  \n",
       "0  2025-08-26 11:30:00  \n",
       "1  2025-08-26 11:30:00  \n",
       "2  2025-08-26 11:30:00  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado en variable: df_permisos\n",
      "\n",
      "AN√ÅLISIS COMPLETADO\n",
      "Variables disponibles:\n",
      "   ‚Ä¢ df_buk_combinado: Todos los datos juntos\n",
      "   ‚Ä¢ df_inasistencias: Datos solo de inasistencias\n",
      "   ‚Ä¢ df_licencias: Datos solo de licencias\n",
      "   ‚Ä¢ df_permisos: Datos solo de permisos\n"
     ]
    }
   ],
   "source": [
    "# === AN√ÅLISIS SEPARADO POR ENDPOINT ===\n",
    "if 'datos_por_endpoint' in globals() and 'df_buk_combinado' in globals():\n",
    "    print(\"AN√ÅLISIS DETALLADO POR ENDPOINT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for endpoint_name, registros in datos_por_endpoint.items():\n",
    "        if registros:  # Solo si hay datos\n",
    "            print(f\"\\nAN√ÅLISIS: {endpoint_name.upper()}\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            # Crear DataFrame espec√≠fico del endpoint\n",
    "            df_endpoint = pd.json_normalize(registros, sep=\"_\")\n",
    "            \n",
    "            print(f\"Registros: {len(df_endpoint):,}\")\n",
    "            print(f\"Columnas: {len(df_endpoint.columns)}\")\n",
    "            \n",
    "            # Mostrar primeras 5 columnas m√°s importantes\n",
    "            print(f\"Columnas principales:\")\n",
    "            for i, col in enumerate(df_endpoint.columns[:5], 1):\n",
    "                valores_unicos = df_endpoint[col].nunique() if col in df_endpoint.columns else 0\n",
    "                print(f\"      {i}. {col} ({valores_unicos} valores √∫nicos)\")\n",
    "            \n",
    "            # Mostrar muestra\n",
    "            print(f\"Muestra de datos:\")\n",
    "            display(df_endpoint.head(3))\n",
    "            \n",
    "            # Guardar DataFrame individual\n",
    "            globals()[f'df_{endpoint_name}'] = df_endpoint\n",
    "            print(f\"Guardado en variable: df_{endpoint_name}\")\n",
    "    \n",
    "    print(f\"\\nAN√ÅLISIS COMPLETADO\")\n",
    "    print(f\"Variables disponibles:\")\n",
    "    print(f\"   ‚Ä¢ df_buk_combinado: Todos los datos juntos\")\n",
    "    for endpoint_name in datos_por_endpoint.keys():\n",
    "        if datos_por_endpoint[endpoint_name]:\n",
    "            print(f\"   ‚Ä¢ df_{endpoint_name}: Datos solo de {endpoint_name}\")\n",
    "\n",
    "else:\n",
    "    print(\"Primero ejecuta la celda de extracci√≥n combinada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "937ed83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>days_count</th>\n",
       "      <th>day_percent</th>\n",
       "      <th>contribution_days</th>\n",
       "      <th>workday_stage</th>\n",
       "      <th>application_date</th>\n",
       "      <th>application_end_date</th>\n",
       "      <th>justification</th>\n",
       "      <th>...</th>\n",
       "      <th>medic_name</th>\n",
       "      <th>risk_type</th>\n",
       "      <th>sequela</th>\n",
       "      <th>incapacities_control</th>\n",
       "      <th>permission_type_id</th>\n",
       "      <th>permission_type_code</th>\n",
       "      <th>paid</th>\n",
       "      <th>time_measure</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105184</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>Ausencia sin licencia m√©dica</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105185</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>Ausencia sin licencia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105250</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>Tramite personal, informado por Manuel Gamboa</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105283</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>Fallecimiento abuelita, se regal√≥ 2 d√≠as y el ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105547</td>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>2025-05-13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>2025-05-16</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>108418</td>\n",
       "      <td>2025-08-18</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-08-18</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>Compensaci√≥n de horas por feria informada por ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>permiso_con_goce</td>\n",
       "      <td>True</td>\n",
       "      <td>per_day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>108485</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>end_working_day</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>permiso</td>\n",
       "      <td>False</td>\n",
       "      <td>per_day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>108586</td>\n",
       "      <td>2025-08-12</td>\n",
       "      <td>2025-08-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-08-12</td>\n",
       "      <td>2025-08-12</td>\n",
       "      <td>Permiso por fallecimiento de t√≠o</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>permiso_con_goce</td>\n",
       "      <td>True</td>\n",
       "      <td>per_day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>108682</td>\n",
       "      <td>2025-08-21</td>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>Permiso por fallecimiento de madre pt1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>permiso_fallecimiento_legal</td>\n",
       "      <td>True</td>\n",
       "      <td>per_day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>108748</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>2025-08-26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>full_working_day</td>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>2025-08-26</td>\n",
       "      <td>Permiso por fallecimiento de madre pt2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>permiso_fallecimiento_legal</td>\n",
       "      <td>True</td>\n",
       "      <td>per_day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id start_date   end_date  days_count  day_percent  contribution_days  \\\n",
       "0    105184 2025-05-05 2025-05-05         1.0          1.0                0.0   \n",
       "1    105185 2025-05-08 2025-05-08         1.0          1.0                0.0   \n",
       "2    105250 2025-05-02 2025-05-02         1.0          1.0                0.0   \n",
       "3    105283 2025-05-08 2025-05-08         1.0          1.0                0.0   \n",
       "4    105547 2025-05-11 2025-05-13         3.0          1.0                0.0   \n",
       "..      ...        ...        ...         ...          ...                ...   \n",
       "229  108418 2025-08-18 2025-08-19         2.0          1.0                0.0   \n",
       "230  108485 2025-08-19 2025-08-19         1.0          0.5                0.0   \n",
       "231  108586 2025-08-12 2025-08-12         1.0          1.0                0.0   \n",
       "232  108682 2025-08-21 2025-08-22         2.0          1.0                0.0   \n",
       "233  108748 2025-08-25 2025-08-26         2.0          1.0                0.0   \n",
       "\n",
       "        workday_stage application_date application_end_date  \\\n",
       "0    full_working_day       2025-05-05           2025-05-05   \n",
       "1    full_working_day       2025-05-08           2025-05-08   \n",
       "2    full_working_day       2025-05-02           2025-05-02   \n",
       "3    full_working_day       2025-05-08           2025-05-08   \n",
       "4    full_working_day       2025-05-14           2025-05-16   \n",
       "..                ...              ...                  ...   \n",
       "229  full_working_day       2025-08-18           2025-08-19   \n",
       "230   end_working_day       2025-08-19           2025-08-19   \n",
       "231  full_working_day       2025-08-12           2025-08-12   \n",
       "232  full_working_day       2025-08-19           2025-08-20   \n",
       "233  full_working_day       2025-08-25           2025-08-26   \n",
       "\n",
       "                                         justification  ...  medic_name  \\\n",
       "0                         Ausencia sin licencia m√©dica  ...         NaN   \n",
       "1                                Ausencia sin licencia  ...         NaN   \n",
       "2        Tramite personal, informado por Manuel Gamboa  ...         NaN   \n",
       "3    Fallecimiento abuelita, se regal√≥ 2 d√≠as y el ...  ...         NaN   \n",
       "4                                                       ...         NaN   \n",
       "..                                                 ...  ...         ...   \n",
       "229  Compensaci√≥n de horas por feria informada por ...  ...         NaN   \n",
       "230                                                     ...         NaN   \n",
       "231                   Permiso por fallecimiento de t√≠o  ...         NaN   \n",
       "232             Permiso por fallecimiento de madre pt1  ...         NaN   \n",
       "233             Permiso por fallecimiento de madre pt2  ...         NaN   \n",
       "\n",
       "    risk_type sequela incapacities_control  permission_type_id  \\\n",
       "0         NaN     NaN                  NaN                 NaN   \n",
       "1         NaN     NaN                  NaN                 NaN   \n",
       "2         NaN     NaN                  NaN                 NaN   \n",
       "3         NaN     NaN                  NaN                 NaN   \n",
       "4         NaN     NaN                  NaN                 NaN   \n",
       "..        ...     ...                  ...                 ...   \n",
       "229       NaN     NaN                  NaN                 4.0   \n",
       "230       NaN     NaN                  NaN                 3.0   \n",
       "231       NaN     NaN                  NaN                 4.0   \n",
       "232       NaN     NaN                  NaN                 8.0   \n",
       "233       NaN     NaN                  NaN                 8.0   \n",
       "\n",
       "            permission_type_code   paid time_measure start_time end_time  \n",
       "0                            NaN    NaN          NaN        NaN      NaN  \n",
       "1                            NaN    NaN          NaN        NaN      NaN  \n",
       "2                            NaN    NaN          NaN        NaN      NaN  \n",
       "3                            NaN    NaN          NaN        NaN      NaN  \n",
       "4                            NaN    NaN          NaN        NaN      NaN  \n",
       "..                           ...    ...          ...        ...      ...  \n",
       "229             permiso_con_goce   True      per_day        NaN      NaN  \n",
       "230                      permiso  False      per_day        NaN      NaN  \n",
       "231             permiso_con_goce   True      per_day        NaN      NaN  \n",
       "232  permiso_fallecimiento_legal   True      per_day        NaN      NaN  \n",
       "233  permiso_fallecimiento_legal   True      per_day        NaN      NaN  \n",
       "\n",
       "[234 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_combinado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5970a3b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Excel does not support datetimes with timezones. Please ensure that datetimes are timezone unaware before writing to Excel.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m nombre_archivo \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitulo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Exportar a Excel con formato UTF-8\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m df_combinado\u001b[38;5;241m.\u001b[39mto_excel(nombre_archivo, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m¬°Reporte exportado exitosamente en formato Excel a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_archivo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistros exportados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_rellenar)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bgacitua\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bgacitua\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2417\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   2404\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2406\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2407\u001b[0m     df,\n\u001b[0;32m   2408\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2416\u001b[0m )\n\u001b[1;32m-> 2417\u001b[0m formatter\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m   2418\u001b[0m     excel_writer,\n\u001b[0;32m   2419\u001b[0m     sheet_name\u001b[38;5;241m=\u001b[39msheet_name,\n\u001b[0;32m   2420\u001b[0m     startrow\u001b[38;5;241m=\u001b[39mstartrow,\n\u001b[0;32m   2421\u001b[0m     startcol\u001b[38;5;241m=\u001b[39mstartcol,\n\u001b[0;32m   2422\u001b[0m     freeze_panes\u001b[38;5;241m=\u001b[39mfreeze_panes,\n\u001b[0;32m   2423\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m   2424\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2425\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m   2426\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bgacitua\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:952\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    949\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 952\u001b[0m     writer\u001b[38;5;241m.\u001b[39m_write_cells(\n\u001b[0;32m    953\u001b[0m         formatted_cells,\n\u001b[0;32m    954\u001b[0m         sheet_name,\n\u001b[0;32m    955\u001b[0m         startrow\u001b[38;5;241m=\u001b[39mstartrow,\n\u001b[0;32m    956\u001b[0m         startcol\u001b[38;5;241m=\u001b[39mstartcol,\n\u001b[0;32m    957\u001b[0m         freeze_panes\u001b[38;5;241m=\u001b[39mfreeze_panes,\n\u001b[0;32m    958\u001b[0m     )\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m need_save:\n",
      "File \u001b[1;32mc:\\Users\\bgacitua\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:486\u001b[0m, in \u001b[0;36mOpenpyxlWriter._write_cells\u001b[1;34m(self, cells, sheet_name, startrow, startcol, freeze_panes)\u001b[0m\n\u001b[0;32m    481\u001b[0m     freeze_panes \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m], freeze_panes)\n\u001b[0;32m    482\u001b[0m     wks\u001b[38;5;241m.\u001b[39mfreeze_panes \u001b[38;5;241m=\u001b[39m wks\u001b[38;5;241m.\u001b[39mcell(\n\u001b[0;32m    483\u001b[0m         row\u001b[38;5;241m=\u001b[39mfreeze_panes[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, column\u001b[38;5;241m=\u001b[39mfreeze_panes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    484\u001b[0m     )\n\u001b[1;32m--> 486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m cells:\n\u001b[0;32m    487\u001b[0m     xcell \u001b[38;5;241m=\u001b[39m wks\u001b[38;5;241m.\u001b[39mcell(\n\u001b[0;32m    488\u001b[0m         row\u001b[38;5;241m=\u001b[39mstartrow \u001b[38;5;241m+\u001b[39m cell\u001b[38;5;241m.\u001b[39mrow \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, column\u001b[38;5;241m=\u001b[39mstartcol \u001b[38;5;241m+\u001b[39m cell\u001b[38;5;241m.\u001b[39mcol \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     xcell\u001b[38;5;241m.\u001b[39mvalue, fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value_with_fmt(cell\u001b[38;5;241m.\u001b[39mval)\n",
      "File \u001b[1;32mc:\\Users\\bgacitua\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:890\u001b[0m, in \u001b[0;36mExcelFormatter.get_formatted_cells\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_formatted_cells\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[ExcelCell]:\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_header(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_body()):\n\u001b[1;32m--> 890\u001b[0m         cell\u001b[38;5;241m.\u001b[39mval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_value(cell\u001b[38;5;241m.\u001b[39mval)\n\u001b[0;32m    891\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m cell\n",
      "File \u001b[1;32mc:\\Users\\bgacitua\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:607\u001b[0m, in \u001b[0;36mExcelFormatter._format_value\u001b[1;34m(self, val)\u001b[0m\n\u001b[0;32m    605\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfloat_format \u001b[38;5;241m%\u001b[39m val)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(val, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtzinfo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel does not support datetimes with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimezones. Please ensure that datetimes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    610\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare timezone unaware before writing to Excel.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    611\u001b[0m     )\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[1;31mValueError\u001b[0m: Excel does not support datetimes with timezones. Please ensure that datetimes are timezone unaware before writing to Excel."
     ]
    }
   ],
   "source": [
    "# === GUARDAR DATOS EXTRA√çDOS EN MYSQL ===\n",
    "import mysql.connector\n",
    "import json\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Verificar que tenemos datos para guardar\n",
    "if 'df_combinado' not in globals() or df_combinado.empty:\n",
    "    print(\"‚ùå ERROR: No hay datos para guardar en MySQL\")\n",
    "    print(\"üí° Ejecuta primero las celdas de extracci√≥n de datos\")\n",
    "else:\n",
    "    print(\"üíæ GUARDANDO DATOS DE BUK EN MYSQL\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # 1. CONECTAR A LA BASE DE DATOS\n",
    "        print(\"üóÑÔ∏è Conectando a la base de datos...\")\n",
    "        \n",
    "        connection = mysql.connector.connect(\n",
    "            host=\"localhost\",\n",
    "            user=\"root\",\n",
    "            password=\"_Cramer2025_\",\n",
    "            database=\"rrhh_app\",\n",
    "            charset='utf8mb4',  # Para soportar caracteres especiales\n",
    "            autocommit=False    # Control manual de commits\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        print(\"‚úÖ Conexi√≥n exitosa a la base de datos MySQL\")\n",
    "        print(f\"üìä Datos a procesar: {len(df_combinado):,} registros\")\n",
    "        \n",
    "        # 2. PROCESAR DATOS POR TIPO DE ENDPOINT\n",
    "        total_insertados = 0\n",
    "        total_actualizados = 0\n",
    "        total_errores = 0\n",
    "        \n",
    "        # Agrupar datos por tipo de endpoint\n",
    "        if '_source_endpoint' in df_combinado.columns:\n",
    "            endpoints_procesados = df_combinado['_source_endpoint'].unique()\n",
    "            print(f\"üìã Endpoints encontrados: {', '.join(endpoints_procesados)}\")\n",
    "            \n",
    "            for endpoint_type in endpoints_procesados:\n",
    "                print(f\"\\nüîÑ Procesando: {endpoint_type.upper()}\")\n",
    "                print(\"-\" * 30)\n",
    "                \n",
    "                # Filtrar datos del endpoint actual\n",
    "                df_endpoint = df_combinado[df_combinado['_source_endpoint'] == endpoint_type]\n",
    "                print(f\"üìä Registros a procesar: {len(df_endpoint)}\")\n",
    "                \n",
    "                insertados_endpoint = 0\n",
    "                actualizados_endpoint = 0\n",
    "                errores_endpoint = 0\n",
    "                \n",
    "                # ===== PROCESAR INASISTENCIAS =====\n",
    "                if endpoint_type == 'inasistencias':\n",
    "                    for index, row in df_endpoint.iterrows():\n",
    "                        try:\n",
    "                            # Extraer campos principales\n",
    "                            absence_id = row.get('id')\n",
    "                            if pd.isna(absence_id) or absence_id == '':\n",
    "                                print(f\"‚ö†Ô∏è Registro sin ID en fila {index}\")\n",
    "                                errores_endpoint += 1\n",
    "                                continue\n",
    "                            \n",
    "                            # Verificar si ya existe\n",
    "                            check_sql = \"SELECT id FROM inasistencias WHERE absence_id = %s\"\n",
    "                            cursor.execute(check_sql, (absence_id,))\n",
    "                            exists = cursor.fetchone()\n",
    "                            \n",
    "                            # Preparar datos para insertar/actualizar\n",
    "                            data_values = {\n",
    "                                'absence_id': absence_id,\n",
    "                                'employee_id': row.get('employee_id'),\n",
    "                                'user_first_name': row.get('user_first_name', ''),\n",
    "                                'user_last_name': row.get('user_last_name', ''),\n",
    "                                'user_rut': row.get('user_rut', ''),\n",
    "                                'absence_type_name': row.get('absence_type_name', ''),\n",
    "                                'start_date': row.get('start_date'),\n",
    "                                'end_date': row.get('end_date'),\n",
    "                                'working_days': row.get('working_days'),\n",
    "                                'application_date': row.get('application_date'),\n",
    "                                'status': row.get('status', ''),\n",
    "                                'reason': row.get('reason', ''),\n",
    "                                'created_at_buk': row.get('created_at'),\n",
    "                                'updated_at_buk': row.get('updated_at'),\n",
    "                                'extracted_at': row.get('_fecha_extraccion')\n",
    "                            }\n",
    "                            \n",
    "                            if exists:\n",
    "                                # ACTUALIZAR registro existente\n",
    "                                update_sql = \"\"\"\n",
    "                                UPDATE inasistencias SET\n",
    "                                    employee_id = %s,\n",
    "                                    user_first_name = %s,\n",
    "                                    user_last_name = %s,\n",
    "                                    user_rut = %s,\n",
    "                                    absence_type_name = %s,\n",
    "                                    start_date = %s,\n",
    "                                    end_date = %s,\n",
    "                                    working_days = %s,\n",
    "                                    application_date = %s,\n",
    "                                    status = %s,\n",
    "                                    reason = %s,\n",
    "                                    created_at_buk = %s,\n",
    "                                    updated_at_buk = %s,\n",
    "                                    extracted_at = %s,\n",
    "                                    updated_at_local = %s\n",
    "                                WHERE absence_id = %s\n",
    "                                \"\"\"\n",
    "                                \n",
    "                                update_values = (\n",
    "                                    data_values['employee_id'],\n",
    "                                    data_values['user_first_name'],\n",
    "                                    data_values['user_last_name'], \n",
    "                                    data_values['user_rut'],\n",
    "                                    data_values['absence_type_name'],\n",
    "                                    data_values['start_date'],\n",
    "                                    data_values['end_date'],\n",
    "                                    data_values['working_days'],\n",
    "                                    data_values['application_date'],\n",
    "                                    data_values['status'],\n",
    "                                    data_values['reason'],\n",
    "                                    data_values['created_at_buk'],\n",
    "                                    data_values['updated_at_buk'],\n",
    "                                    data_values['extracted_at'],\n",
    "                                    datetime.now(),\n",
    "                                    absence_id\n",
    "                                )\n",
    "                                \n",
    "                                cursor.execute(update_sql, update_values)\n",
    "                                actualizados_endpoint += 1\n",
    "                                \n",
    "                            else:\n",
    "                                # INSERTAR nuevo registro\n",
    "                                insert_sql = \"\"\"\n",
    "                                INSERT INTO inasistencias (\n",
    "                                    absence_id, employee_id, user_first_name, user_last_name,\n",
    "                                    user_rut, absence_type_name, start_date, end_date,\n",
    "                                    working_days, application_date, status, reason,\n",
    "                                    created_at_buk, updated_at_buk, extracted_at,\n",
    "                                    created_at_local, updated_at_local\n",
    "                                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                                \"\"\"\n",
    "                                \n",
    "                                insert_values = (\n",
    "                                    data_values['absence_id'],\n",
    "                                    data_values['employee_id'],\n",
    "                                    data_values['user_first_name'],\n",
    "                                    data_values['user_last_name'],\n",
    "                                    data_values['user_rut'],\n",
    "                                    data_values['absence_type_name'],\n",
    "                                    data_values['start_date'],\n",
    "                                    data_values['end_date'],\n",
    "                                    data_values['working_days'],\n",
    "                                    data_values['application_date'],\n",
    "                                    data_values['status'],\n",
    "                                    data_values['reason'],\n",
    "                                    data_values['created_at_buk'],\n",
    "                                    data_values['updated_at_buk'],\n",
    "                                    data_values['extracted_at'],\n",
    "                                    datetime.now(),\n",
    "                                    datetime.now()\n",
    "                                )\n",
    "                                \n",
    "                                cursor.execute(insert_sql, insert_values)\n",
    "                                insertados_endpoint += 1\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            errores_endpoint += 1\n",
    "                            print(f\"‚ùå Error procesando inasistencia {absence_id}: {e}\")\n",
    "                            continue\n",
    "                \n",
    "                # ===== PROCESAR LICENCIAS =====\n",
    "                elif endpoint_type == 'licencias':\n",
    "                    for index, row in df_endpoint.iterrows():\n",
    "                        try:\n",
    "                            licence_id = row.get('id')\n",
    "                            if pd.isna(licence_id) or licence_id == '':\n",
    "                                errores_endpoint += 1\n",
    "                                continue\n",
    "                            \n",
    "                            # Verificar existencia\n",
    "                            check_sql = \"SELECT id FROM licencias WHERE licence_id = %s\"\n",
    "                            cursor.execute(check_sql, (licence_id,))\n",
    "                            exists = cursor.fetchone()\n",
    "                            \n",
    "                            # Preparar datos\n",
    "                            data_values = {\n",
    "                                'licence_id': licence_id,\n",
    "                                'employee_id': row.get('employee_id'),\n",
    "                                'user_first_name': row.get('user_first_name', ''),\n",
    "                                'user_last_name': row.get('user_last_name', ''),\n",
    "                                'licence_type_name': row.get('licence_type_name', ''),\n",
    "                                'start_date': row.get('start_date'),\n",
    "                                'end_date': row.get('end_date'),\n",
    "                                'working_days': row.get('working_days'),\n",
    "                                'status': row.get('status', ''),\n",
    "                                'created_at_buk': row.get('created_at'),\n",
    "                                'updated_at_buk': row.get('updated_at'),\n",
    "                                'extracted_at': row.get('_fecha_extraccion')\n",
    "                            }\n",
    "                            \n",
    "                            if exists:\n",
    "                                # Actualizar licencia\n",
    "                                update_sql = \"\"\"\n",
    "                                UPDATE licencias SET\n",
    "                                    employee_id = %s, user_first_name = %s, user_last_name = %s,\n",
    "                                    licence_type_name = %s, start_date = %s, end_date = %s,\n",
    "                                    working_days = %s, status = %s, updated_at_buk = %s,\n",
    "                                    extracted_at = %s, updated_at_local = %s\n",
    "                                WHERE licence_id = %s\n",
    "                                \"\"\"\n",
    "                                \n",
    "                                cursor.execute(update_sql, (\n",
    "                                    data_values['employee_id'], data_values['user_first_name'],\n",
    "                                    data_values['user_last_name'], data_values['licence_type_name'],\n",
    "                                    data_values['start_date'], data_values['end_date'],\n",
    "                                    data_values['working_days'], data_values['status'],\n",
    "                                    data_values['updated_at_buk'], data_values['extracted_at'],\n",
    "                                    datetime.now(), licence_id\n",
    "                                ))\n",
    "                                actualizados_endpoint += 1\n",
    "                            else:\n",
    "                                # Insertar nueva licencia\n",
    "                                insert_sql = \"\"\"\n",
    "                                INSERT INTO licencias (\n",
    "                                    licence_id, employee_id, user_first_name, user_last_name,\n",
    "                                    licence_type_name, start_date, end_date, working_days,\n",
    "                                    status, created_at_buk, updated_at_buk, extracted_at,\n",
    "                                    created_at_local, updated_at_local\n",
    "                                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                                \"\"\"\n",
    "                                \n",
    "                                cursor.execute(insert_sql, (\n",
    "                                    data_values['licence_id'], data_values['employee_id'],\n",
    "                                    data_values['user_first_name'], data_values['user_last_name'],\n",
    "                                    data_values['licence_type_name'], data_values['start_date'],\n",
    "                                    data_values['end_date'], data_values['working_days'],\n",
    "                                    data_values['status'], data_values['created_at_buk'],\n",
    "                                    data_values['updated_at_buk'], data_values['extracted_at'],\n",
    "                                    datetime.now(), datetime.now()\n",
    "                                ))\n",
    "                                insertados_endpoint += 1\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            errores_endpoint += 1\n",
    "                            print(f\"‚ùå Error procesando licencia {licence_id}: {e}\")\n",
    "                            continue\n",
    "                \n",
    "                # ===== PROCESAR PERMISOS =====\n",
    "                elif endpoint_type == 'permisos':\n",
    "                    for index, row in df_endpoint.iterrows():\n",
    "                        try:\n",
    "                            permission_id = row.get('id')\n",
    "                            if pd.isna(permission_id) or permission_id == '':\n",
    "                                errores_endpoint += 1\n",
    "                                continue\n",
    "                            \n",
    "                            # Verificar existencia\n",
    "                            check_sql = \"SELECT id FROM permisos WHERE permission_id = %s\"\n",
    "                            cursor.execute(check_sql, (permission_id,))\n",
    "                            exists = cursor.fetchone()\n",
    "                            \n",
    "                            # Preparar datos\n",
    "                            data_values = {\n",
    "                                'permission_id': permission_id,\n",
    "                                'employee_id': row.get('employee_id'),\n",
    "                                'user_first_name': row.get('user_first_name', ''),\n",
    "                                'user_last_name': row.get('user_last_name', ''),\n",
    "                                'permission_type_name': row.get('permission_type_name', ''),\n",
    "                                'start_date': row.get('start_date'),\n",
    "                                'end_date': row.get('end_date'),\n",
    "                                'status': row.get('status', ''),\n",
    "                                'reason': row.get('reason', ''),\n",
    "                                'created_at_buk': row.get('created_at'),\n",
    "                                'updated_at_buk': row.get('updated_at'),\n",
    "                                'extracted_at': row.get('_fecha_extraccion')\n",
    "                            }\n",
    "                            \n",
    "                            if exists:\n",
    "                                # Actualizar permiso\n",
    "                                update_sql = \"\"\"\n",
    "                                UPDATE permisos SET\n",
    "                                    employee_id = %s, user_first_name = %s, user_last_name = %s,\n",
    "                                    permission_type_name = %s, start_date = %s, end_date = %s,\n",
    "                                    status = %s, reason = %s, updated_at_buk = %s,\n",
    "                                    extracted_at = %s, updated_at_local = %s\n",
    "                                WHERE permission_id = %s\n",
    "                                \"\"\"\n",
    "                                \n",
    "                                cursor.execute(update_sql, (\n",
    "                                    data_values['employee_id'], data_values['user_first_name'],\n",
    "                                    data_values['user_last_name'], data_values['permission_type_name'],\n",
    "                                    data_values['start_date'], data_values['end_date'],\n",
    "                                    data_values['status'], data_values['reason'],\n",
    "                                    data_values['updated_at_buk'], data_values['extracted_at'],\n",
    "                                    datetime.now(), permission_id\n",
    "                                ))\n",
    "                                actualizados_endpoint += 1\n",
    "                            else:\n",
    "                                # Insertar nuevo permiso\n",
    "                                insert_sql = \"\"\"\n",
    "                                INSERT INTO permisos (\n",
    "                                    permission_id, employee_id, user_first_name, user_last_name,\n",
    "                                    permission_type_name, start_date, end_date, status, reason,\n",
    "                                    created_at_buk, updated_at_buk, extracted_at,\n",
    "                                    created_at_local, updated_at_local\n",
    "                                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                                \"\"\"\n",
    "                                \n",
    "                                cursor.execute(insert_sql, (\n",
    "                                    data_values['permission_id'], data_values['employee_id'],\n",
    "                                    data_values['user_first_name'], data_values['user_last_name'],\n",
    "                                    data_values['permission_type_name'], data_values['start_date'],\n",
    "                                    data_values['end_date'], data_values['status'],\n",
    "                                    data_values['reason'], data_values['created_at_buk'],\n",
    "                                    data_values['updated_at_buk'], data_values['extracted_at'],\n",
    "                                    datetime.now(), datetime.now()\n",
    "                                ))\n",
    "                                insertados_endpoint += 1\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            errores_endpoint += 1\n",
    "                            print(f\"‚ùå Error procesando permiso {permission_id}: {e}\")\n",
    "                            continue\n",
    "                \n",
    "                # Mostrar resultados del endpoint\n",
    "                print(f\"‚úÖ {endpoint_type}: {insertados_endpoint} insertados, {actualizados_endpoint} actualizados, {errores_endpoint} errores\")\n",
    "                \n",
    "                # Sumar a totales\n",
    "                total_insertados += insertados_endpoint\n",
    "                total_actualizados += actualizados_endpoint\n",
    "                total_errores += errores_endpoint\n",
    "            \n",
    "            # 3. CONFIRMAR TRANSACCI√ìN\n",
    "            connection.commit()\n",
    "            \n",
    "            print(f\"\\n\" + \"=\" * 50)\n",
    "            print(f\"‚úÖ PROCESO COMPLETADO EXITOSAMENTE\")\n",
    "            print(f\"üìä RESUMEN FINAL:\")\n",
    "            print(f\"   ‚Ä¢ Total insertados: {total_insertados}\")\n",
    "            print(f\"   ‚Ä¢ Total actualizados: {total_actualizados}\")\n",
    "            print(f\"   ‚Ä¢ Total errores: {total_errores}\")\n",
    "            print(f\"   ‚Ä¢ Fecha de procesamiento: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(f\"   ‚Ä¢ Per√≠odo de datos: {info_extraccion.get('fecha_inicio', 'N/A')} a {info_extraccion.get('fecha_fin', 'N/A')}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå ERROR: Los datos no tienen informaci√≥n de endpoint de origen\")\n",
    "            print(\"üí° Verifica que la extracci√≥n se haya realizado correctamente\")\n",
    "            \n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"‚ùå Error de base de datos MySQL: {e}\")\n",
    "        if 'connection' in locals():\n",
    "            connection.rollback()\n",
    "            print(\"üîÑ Transacci√≥n revertida\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inesperado: {e}\")\n",
    "        print(f\"   Tipo: {type(e).__name__}\")\n",
    "        if 'connection' in locals():\n",
    "            connection.rollback()\n",
    "            print(\"üîÑ Transacci√≥n revertida\")\n",
    "    \n",
    "    finally:\n",
    "        # Cerrar conexiones siempre\n",
    "        if 'cursor' in locals():\n",
    "            cursor.close()\n",
    "        if 'connection' in locals() and connection.is_connected():\n",
    "            connection.close()\n",
    "            print(\"üîå Conexi√≥n a MySQL cerrada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79a3bdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä EXPORTANDO df_combinado A EXCEL (CORRIGIENDO TIMEZONES)\n",
      "============================================================\n",
      "üìÑ Archivo: Reporte_API_BUK_20250826_114028.xlsx\n",
      "üìÅ Ubicaci√≥n: C:\\Users\\bgacitua\\Desktop\\Repositorio_GitHub\\Scripts de Python\\Solicitud API\\Archivos generados\n",
      "\n",
      "üìã Informaci√≥n antes de procesar:\n",
      "   ‚Ä¢ Filas: 234\n",
      "   ‚Ä¢ Columnas: 37\n",
      "\n",
      "üïê Procesando columnas de fecha/hora...\n",
      "   üîç Verificando columna objeto: created_at\n",
      "      ‚úÖ created_at procesada como fecha\n",
      "   üîç Verificando columna objeto: updated_at\n",
      "      ‚úÖ updated_at procesada como fecha\n",
      "\n",
      "üìä Resumen de conversiones:\n",
      "   ‚Ä¢ Columnas de fecha convertidas: 2\n",
      "\n",
      "üíæ Exportando a Excel...\n",
      "\n",
      "‚úÖ ¬°EXPORTACI√ìN EXITOSA!\n",
      "   üìÑ Archivo: Reporte_API_BUK_20250826_114028.xlsx\n",
      "   üìä Registros exportados: 234\n",
      "   üìã Columnas exportadas: 37\n",
      "   üìä Tama√±o del archivo: 0.04 MB\n",
      "   üìÅ Ubicaci√≥n: C:\\Users\\bgacitua\\Desktop\\Repositorio_GitHub\\Scripts de Python\\Solicitud API\\Archivos generados\\Reporte_API_BUK_20250826_114028.xlsx\n",
      "\n",
      "üìà DETALLES DEL ARCHIVO:\n",
      "   ‚Ä¢ Distribuci√≥n por endpoint:\n",
      "     - Licencias: 162 registros\n",
      "     - Inasistencias: 36 registros\n",
      "     - Permisos: 36 registros\n"
     ]
    }
   ],
   "source": [
    "# === EXPORTAR df_combinado A EXCEL (SOLUCIONANDO PROBLEMA DE TIMEZONE) ===\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Verificar que el DataFrame existe\n",
    "if 'df_combinado' in globals() and not df_combinado.empty:\n",
    "    print(\"üìä EXPORTANDO df_combinado A EXCEL (CORRIGIENDO TIMEZONES)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Configurar nombre del archivo\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        titulo = \"Reporte_API_BUK\"\n",
    "        nombre_archivo = f\"{titulo}_{timestamp}.xlsx\"\n",
    "        \n",
    "        # Crear ruta completa\n",
    "        ruta_base = r\"C:\\Users\\bgacitua\\Desktop\\Repositorio_GitHub\\Scripts de Python\\Solicitud API\\Archivos generados\"\n",
    "        \n",
    "        # Verificar si la carpeta existe, si no crearla\n",
    "        if not os.path.exists(ruta_base):\n",
    "            os.makedirs(ruta_base)\n",
    "            print(f\"üìÅ Carpeta creada: {ruta_base}\")\n",
    "        \n",
    "        ruta_completa = os.path.join(ruta_base, nombre_archivo)\n",
    "        \n",
    "        print(f\"üìÑ Archivo: {nombre_archivo}\")\n",
    "        print(f\"üìÅ Ubicaci√≥n: {ruta_base}\")\n",
    "        \n",
    "        # üîß PASO 1: CREAR COPIA DEL DATAFRAME PARA NO AFECTAR EL ORIGINAL\n",
    "        df_para_exportar = df_combinado.copy()\n",
    "        \n",
    "        print(f\"\\nüìã Informaci√≥n antes de procesar:\")\n",
    "        print(f\"   ‚Ä¢ Filas: {len(df_para_exportar):,}\")\n",
    "        print(f\"   ‚Ä¢ Columnas: {len(df_para_exportar.columns)}\")\n",
    "        \n",
    "        # üîß PASO 2: DETECTAR Y CONVERTIR COLUMNAS CON TIMEZONE\n",
    "        columnas_fecha_convertidas = 0\n",
    "        columnas_problematicas = []\n",
    "        \n",
    "        print(f\"\\nüïê Procesando columnas de fecha/hora...\")\n",
    "        \n",
    "        for columna in df_para_exportar.columns:\n",
    "            # Verificar si la columna contiene datos datetime\n",
    "            if df_para_exportar[columna].dtype == 'datetime64[ns, UTC]' or \\\n",
    "               (hasattr(df_para_exportar[columna].dtype, 'tz') and df_para_exportar[columna].dtype.tz is not None):\n",
    "                \n",
    "                print(f\"   üîÑ Convirtiendo: {columna}\")\n",
    "                try:\n",
    "                    # Convertir a timezone naive (sin zona horaria)\n",
    "                    if hasattr(df_para_exportar[columna].dt, 'tz_localize'):\n",
    "                        # Si tiene timezone, convertir a naive\n",
    "                        df_para_exportar[columna] = df_para_exportar[columna].dt.tz_localize(None)\n",
    "                    elif hasattr(df_para_exportar[columna].dt, 'tz_convert'):\n",
    "                        # Si tiene timezone, convertir a naive\n",
    "                        df_para_exportar[columna] = df_para_exportar[columna].dt.tz_convert(None)\n",
    "                    \n",
    "                    columnas_fecha_convertidas += 1\n",
    "                    print(f\"      ‚úÖ {columna} convertida exitosamente\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    columnas_problematicas.append(columna)\n",
    "                    print(f\"      ‚ö†Ô∏è Problema con {columna}: {e}\")\n",
    "                    \n",
    "                    # Intentar conversi√≥n alternativa\n",
    "                    try:\n",
    "                        df_para_exportar[columna] = pd.to_datetime(df_para_exportar[columna], errors='coerce', utc=False)\n",
    "                        print(f\"      üîÑ Conversi√≥n alternativa exitosa para {columna}\")\n",
    "                    except:\n",
    "                        # Como √∫ltimo recurso, convertir a string\n",
    "                        df_para_exportar[columna] = df_para_exportar[columna].astype(str)\n",
    "                        print(f\"      üìù Convertido a texto: {columna}\")\n",
    "        \n",
    "        # Tambi√©n revisar columnas object que podr√≠an ser fechas\n",
    "        for columna in df_para_exportar.select_dtypes(include=['object']).columns:\n",
    "            # Verificar si parece una fecha\n",
    "            if any(keyword in columna.lower() for keyword in ['date', 'time', 'created', 'updated']):\n",
    "                muestra = df_para_exportar[columna].dropna().head(3)\n",
    "                if len(muestra) > 0 and any('T' in str(val) or '-' in str(val) for val in muestra):\n",
    "                    try:\n",
    "                        print(f\"   üîç Verificando columna objeto: {columna}\")\n",
    "                        df_para_exportar[columna] = pd.to_datetime(df_para_exportar[columna], errors='coerce', utc=False)\n",
    "                        # Si se convirti√≥ exitosamente y tiene timezone, quitarla\n",
    "                        if hasattr(df_para_exportar[columna].dtype, 'tz') and df_para_exportar[columna].dtype.tz is not None:\n",
    "                            df_para_exportar[columna] = df_para_exportar[columna].dt.tz_localize(None)\n",
    "                        columnas_fecha_convertidas += 1\n",
    "                        print(f\"      ‚úÖ {columna} procesada como fecha\")\n",
    "                    except:\n",
    "                        pass  # Si no se puede convertir, dejarlo como est√°\n",
    "        \n",
    "        print(f\"\\nüìä Resumen de conversiones:\")\n",
    "        print(f\"   ‚Ä¢ Columnas de fecha convertidas: {columnas_fecha_convertidas}\")\n",
    "        if columnas_problematicas:\n",
    "            print(f\"   ‚Ä¢ Columnas con problemas: {len(columnas_problematicas)}\")\n",
    "            for col in columnas_problematicas:\n",
    "                print(f\"     - {col}\")\n",
    "        \n",
    "        # üîß PASO 3: EXPORTAR A EXCEL\n",
    "        print(f\"\\nüíæ Exportando a Excel...\")\n",
    "        df_para_exportar.to_excel(ruta_completa, index=False, engine='openpyxl')\n",
    "        \n",
    "        # üîß PASO 4: VERIFICAR √âXITO\n",
    "        if os.path.exists(ruta_completa):\n",
    "            tama√±o_archivo = os.path.getsize(ruta_completa) / 1024**2  # MB\n",
    "            print(f\"\\n‚úÖ ¬°EXPORTACI√ìN EXITOSA!\")\n",
    "            print(f\"   üìÑ Archivo: {nombre_archivo}\")\n",
    "            print(f\"   üìä Registros exportados: {len(df_para_exportar):,}\")\n",
    "            print(f\"   üìã Columnas exportadas: {len(df_para_exportar.columns)}\")\n",
    "            print(f\"   üìä Tama√±o del archivo: {tama√±o_archivo:.2f} MB\")\n",
    "            print(f\"   üìÅ Ubicaci√≥n: {ruta_completa}\")\n",
    "            \n",
    "            # Mostrar informaci√≥n adicional\n",
    "            print(f\"\\nüìà DETALLES DEL ARCHIVO:\")\n",
    "            if '_source_endpoint' in df_para_exportar.columns:\n",
    "                print(f\"   ‚Ä¢ Distribuci√≥n por endpoint:\")\n",
    "                conteo = df_para_exportar['_source_endpoint'].value_counts()\n",
    "                for endpoint, cantidad in conteo.items():\n",
    "                    print(f\"     - {endpoint.capitalize()}: {cantidad:,} registros\")\n",
    "                    \n",
    "        else:\n",
    "            print(f\"‚ùå Error: No se pudo crear el archivo\")\n",
    "            \n",
    "    except PermissionError:\n",
    "        print(f\"‚ùå ERROR DE PERMISOS:\")\n",
    "        print(f\"   ‚Ä¢ El archivo puede estar abierto en Excel\")\n",
    "        print(f\"   ‚Ä¢ Cierra Excel y prueba nuevamente\")\n",
    "        print(f\"   ‚Ä¢ O cambia la ubicaci√≥n del archivo\")\n",
    "        \n",
    "        # Intentar en el escritorio como alternativa\n",
    "        try:\n",
    "            print(f\"\\nüîÑ Intentando guardar en el Escritorio...\")\n",
    "            escritorio = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "            ruta_escritorio = os.path.join(escritorio, nombre_archivo)\n",
    "            df_para_exportar.to_excel(ruta_escritorio, index=False, engine='openpyxl')\n",
    "            print(f\"‚úÖ Guardado en el Escritorio: {ruta_escritorio}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Tambi√©n fall√≥ en el Escritorio: {e2}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR INESPERADO: {e}\")\n",
    "        print(f\"   Tipo: {type(e).__name__}\")\n",
    "        \n",
    "        # Opci√≥n de respaldo: exportar como CSV\n",
    "        try:\n",
    "            print(f\"\\nüîÑ Intentando exportar como CSV...\")\n",
    "            nombre_csv = f\"{titulo}_{timestamp}.csv\"\n",
    "            ruta_csv = os.path.join(ruta_base, nombre_csv)\n",
    "            df_para_exportar.to_csv(ruta_csv, index=False, encoding='utf-8-sig')\n",
    "            print(f\"‚úÖ Archivo CSV creado exitosamente: {ruta_csv}\")\n",
    "        except Exception as e3:\n",
    "            print(f\"‚ùå Tambi√©n fall√≥ el CSV: {e3}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå ERROR: df_combinado no existe o est√° vac√≠o\")\n",
    "    print(\"üí° Ejecuta primero las celdas de extracci√≥n de datos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
